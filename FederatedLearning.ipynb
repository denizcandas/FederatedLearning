{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FederatedLearning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHZjayhFfoyL"
      },
      "source": [
        "This notebook uses https://nextjournal.com/gkoehler/pytorch-mnist as a basis to\r\n",
        "apply federated learning concepts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoG-lQ3ngsJ7"
      },
      "source": [
        "Let's start with importing some necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkIJXQhrfyCD"
      },
      "source": [
        "import torch\r\n",
        "import torchvision\r\n",
        "import random\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twI8Z_GtigqK"
      },
      "source": [
        "And define our main variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdpkH0Wufzpn"
      },
      "source": [
        "user_count = 10\r\n",
        "user_fraction = 0.3\r\n",
        "c_epochs = 52  # central epochs\r\n",
        "c_rate = 0.5  # central learning rate (relevant if fed_svg == True)\r\n",
        "learning_rate = 0.01  # local\r\n",
        "momentum = 0.5  # local\r\n",
        "fed_sgd = True  # use fed_avg when False\r\n",
        "local_epochs = 10 # relevant if fed_svg == False"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTZa5hCeg2iy"
      },
      "source": [
        "Now, for the network, train and test definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYHKgpNufgLs"
      },
      "source": [
        "class Net(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Net, self).__init__()\r\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\r\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\r\n",
        "        self.conv2_drop = nn.Dropout2d()\r\n",
        "        self.fc1 = nn.Linear(320, 50)\r\n",
        "        self.fc2 = nn.Linear(50, 10)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\r\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\r\n",
        "        x = x.view(-1, 320)\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = F.dropout(x, training=self.training)\r\n",
        "        x = self.fc2(x)\r\n",
        "        return F.log_softmax(x)\r\n",
        "\r\n",
        "\r\n",
        "def train(network, data, target):\r\n",
        "    iterations = 1\r\n",
        "    l_epochs = 1\r\n",
        "    if not fed_sgd:\r\n",
        "        data = torch.split(data, 64)  # split into 64 part batches if using fed_avg\r\n",
        "        iterations = len(data)\r\n",
        "        print(\"We got \" + str(iterations) + \" iterations\")\r\n",
        "        target = torch.split(target, 64)\r\n",
        "        l_epochs = local_epochs\r\n",
        "    else:\r\n",
        "        data = [data]  # wrap data in an array so that data has always the same nesting count\r\n",
        "        target = [target]\r\n",
        "\r\n",
        "    for local_epoch in range(l_epochs):\r\n",
        "        for i in range(iterations):\r\n",
        "            global train_losses\r\n",
        "            optimizer = optim.SGD(network.parameters(), lr=learning_rate,\r\n",
        "                                  momentum=momentum)\r\n",
        "            network.train()\r\n",
        "            optimizer.zero_grad()\r\n",
        "            output = network(data[i])\r\n",
        "            loss = F.nll_loss(output, target[i])\r\n",
        "            loss.backward()\r\n",
        "            if not fed_sgd:\r\n",
        "                optimizer.step()\r\n",
        "                optimizer.zero_grad()\r\n",
        "        train_losses.append(loss)\r\n",
        "        print(f'Local epoch: {local_epoch}, Batch loss: {loss}')\r\n",
        "    if fed_sgd:\r\n",
        "        # https://discuss.pytorch.org/t/please-help-how-can-copy-the-gradient-from-net-a-to-net-b/41226/5\r\n",
        "        return [param[1].grad for param in network.named_parameters()]\r\n",
        "    else:\r\n",
        "        return network.state_dict()\r\n",
        "\r\n",
        "\r\n",
        "def test(network):\r\n",
        "    network.eval()\r\n",
        "    test_loss = 0\r\n",
        "    correct = 0\r\n",
        "    with torch.no_grad():\r\n",
        "        for data, target in test_loader:\r\n",
        "            output = network(data)\r\n",
        "            test_loss += F.nll_loss(output, target, size_average=False).item()\r\n",
        "            pred = output.data.max(1, keepdim=True)[1]\r\n",
        "            correct += pred.eq(target.data.view_as(pred)).sum()\r\n",
        "    test_loss /= len(test_loader.dataset)\r\n",
        "    print('Test set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\r\n",
        "        test_loss, correct, len(test_loader.dataset),\r\n",
        "        100. * correct / len(test_loader.dataset)))\r\n",
        "    return test_loss"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTxCIj3MiLlw"
      },
      "source": [
        "Load up the MNIST Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHDZyO_ViB6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41260efe-c893-465a-f7ed-ffbc6f36de1c"
      },
      "source": [
        "batch_size_test = 1000\r\n",
        "random_seed = 1\r\n",
        "torch.backends.cudnn.enabled = False\r\n",
        "torch.manual_seed(random_seed)\r\n",
        "user_data = []\r\n",
        "user_target = []\r\n",
        "\r\n",
        "\r\n",
        "def train_loader(user_count):\r\n",
        "    return torch.utils.data.DataLoader(\r\n",
        "        torchvision.datasets.MNIST('/files/', train=True, download=True,\r\n",
        "                                   transform=torchvision.transforms.Compose([\r\n",
        "                                       torchvision.transforms.ToTensor(),\r\n",
        "                                       torchvision.transforms.Normalize(\r\n",
        "                                           (0.1307,), (0.3081,))\r\n",
        "                                   ])),\r\n",
        "        batch_size=60000 // user_count, shuffle=True)\r\n",
        "\r\n",
        "test_loader = torch.utils.data.DataLoader(\r\n",
        "    torchvision.datasets.MNIST('/files/', train=False, download=True,\r\n",
        "                               transform=torchvision.transforms.Compose([\r\n",
        "                                   torchvision.transforms.ToTensor(),\r\n",
        "                                   torchvision.transforms.Normalize(\r\n",
        "                                       (0.1307,), (0.3081,))\r\n",
        "                               ])),\r\n",
        "    batch_size=batch_size_test, shuffle=True)\r\n",
        "\r\n",
        "\r\n",
        "# make sure the data is fully distributed\r\n",
        "for batch_idx, (data, target) in enumerate(train_loader(user_count)):\r\n",
        "    print('Preparing data for user', batch_idx)\r\n",
        "    user_data.append(data)\r\n",
        "    user_target.append(target)\r\n",
        "print('Data loaded')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing data for user 0\n",
            "Preparing data for user 1\n",
            "Preparing data for user 2\n",
            "Preparing data for user 3\n",
            "Preparing data for user 4\n",
            "Preparing data for user 5\n",
            "Preparing data for user 6\n",
            "Preparing data for user 7\n",
            "Preparing data for user 8\n",
            "Preparing data for user 9\n",
            "Data loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olrpRaXlfgmL"
      },
      "source": [
        "And start training on multiple user networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCYAQJSFgYp2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f997eb69-0a73-4dff-dd38-7dfd52b95b26"
      },
      "source": [
        "active_user_count = int(user_count * user_fraction)\r\n",
        "network_list = []\r\n",
        "train_losses = []\r\n",
        "\r\n",
        "cn = Net()  # central_network\r\n",
        "for user in range(user_count):\r\n",
        "    network_list.append(Net())\r\n",
        "\r\n",
        "optimizer = torch.optim.SGD(cn.parameters(), lr=c_rate, momentum=0.5)\r\n",
        "\r\n",
        "test_losses = [test(cn)]\r\n",
        "\r\n",
        "for c_epoch in range(c_epochs):\r\n",
        "    print(f'GLOBAL EPOCH {c_epoch}')\r\n",
        "    chosen_users = random.sample(range(user_count), active_user_count)\r\n",
        "    if fed_sgd:\r\n",
        "        for user_number in chosen_users:\r\n",
        "            user_net = network_list[user_number]\r\n",
        "            user_net.load_state_dict(cn.state_dict())\r\n",
        "            print(f'Local user {user_number}: ', end='')\r\n",
        "            for cn_param, user_gradient in zip(cn.named_parameters(),\r\n",
        "                                               train(user_net, user_data[user_number],\r\n",
        "                                                     user_target[user_number])):\r\n",
        "                if cn_param[1].grad is not None:\r\n",
        "                    cn_param[1].grad += user_gradient.clone() / active_user_count\r\n",
        "                else:\r\n",
        "                    cn_param[1].grad = user_gradient.clone() / active_user_count\r\n",
        "        optimizer.step()\r\n",
        "        optimizer.zero_grad()\r\n",
        "    else:\r\n",
        "        weights = []\r\n",
        "        for user_number in chosen_users:\r\n",
        "            user_net = network_list[user_number]\r\n",
        "            user_net.load_state_dict(cn.state_dict())\r\n",
        "            print(f'Local user {user_number}: ', end='')\r\n",
        "            user_weight = train(user_net, user_data[user_number],\r\n",
        "                                user_target[user_number])\r\n",
        "            weights.append(user_weight)\r\n",
        "        weights_average = {}\r\n",
        "        first_user = True\r\n",
        "        for user_weight in weights:\r\n",
        "            for (key, value) in user_weight.items():\r\n",
        "                if first_user:\r\n",
        "                    weights_average[key] = value / active_user_count\r\n",
        "                else:\r\n",
        "                    weights_average[key] += value / active_user_count\r\n",
        "            first_user = False\r\n",
        "        cn.load_state_dict(weights_average)\r\n",
        "    print(f'Global epoch {c_epoch}: ', end='')\r\n",
        "    test_losses.append(test(cn))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Avg. loss: 2.2994, Accuracy: 1428/10000 (14%)\n",
            "\n",
            "GLOBAL EPOCH 0\n",
            "Local user 4: Local epoch: 0, Batch loss: 2.309497117996216\n",
            "Local user 9: Local epoch: 0, Batch loss: 2.3077046871185303\n",
            "Local user 3: Local epoch: 0, Batch loss: 2.3094234466552734\n",
            "Global epoch 0: Test set: Avg. loss: 2.2657, Accuracy: 2865/10000 (29%)\n",
            "\n",
            "GLOBAL EPOCH 1\n",
            "Local user 3: Local epoch: 0, Batch loss: 2.2731807231903076\n",
            "Local user 8: Local epoch: 0, Batch loss: 2.273749828338623\n",
            "Local user 0: Local epoch: 0, Batch loss: 2.2729954719543457\n",
            "Global epoch 1: Test set: Avg. loss: 2.2138, Accuracy: 3859/10000 (39%)\n",
            "\n",
            "GLOBAL EPOCH 2\n",
            "Local user 7: Local epoch: 0, Batch loss: 2.2321434020996094\n",
            "Local user 0: Local epoch: 0, Batch loss: 2.231135368347168\n",
            "Local user 5: Local epoch: 0, Batch loss: 2.231928825378418\n",
            "Global epoch 2: Test set: Avg. loss: 2.0876, Accuracy: 5852/10000 (59%)\n",
            "\n",
            "GLOBAL EPOCH 3\n",
            "Local user 5: Local epoch: 0, Batch loss: 2.1391565799713135\n",
            "Local user 3: Local epoch: 0, Batch loss: 2.139261245727539\n",
            "Local user 4: Local epoch: 0, Batch loss: 2.129934787750244\n",
            "Global epoch 3: Test set: Avg. loss: 1.7779, Accuracy: 6514/10000 (65%)\n",
            "\n",
            "GLOBAL EPOCH 4\n",
            "Local user 9: Local epoch: 0, Batch loss: 1.9310081005096436\n",
            "Local user 3: Local epoch: 0, Batch loss: 1.9394240379333496\n",
            "Local user 7: Local epoch: 0, Batch loss: 1.9535454511642456\n",
            "Global epoch 4: Test set: Avg. loss: 1.5360, Accuracy: 4533/10000 (45%)\n",
            "\n",
            "GLOBAL EPOCH 5\n",
            "Local user 5: Local epoch: 0, Batch loss: 1.901923656463623\n",
            "Local user 0: Local epoch: 0, Batch loss: 1.868073582649231\n",
            "Local user 6: Local epoch: 0, Batch loss: 1.860231637954712\n",
            "Global epoch 5: Test set: Avg. loss: 2.2982, Accuracy: 2105/10000 (21%)\n",
            "\n",
            "GLOBAL EPOCH 6\n",
            "Local user 4: Local epoch: 0, Batch loss: 2.5404117107391357\n",
            "Local user 8: Local epoch: 0, Batch loss: 2.5436477661132812\n",
            "Local user 9: Local epoch: 0, Batch loss: 2.551574945449829\n",
            "Global epoch 6: Test set: Avg. loss: 2.2802, Accuracy: 1754/10000 (18%)\n",
            "\n",
            "GLOBAL EPOCH 7\n",
            "Local user 0: Local epoch: 0, Batch loss: 2.280132532119751\n",
            "Local user 6: Local epoch: 0, Batch loss: 2.280409812927246\n",
            "Local user 2: Local epoch: 0, Batch loss: 2.2815423011779785\n",
            "Global epoch 7: Test set: Avg. loss: 2.2279, Accuracy: 1949/10000 (19%)\n",
            "\n",
            "GLOBAL EPOCH 8\n",
            "Local user 9: Local epoch: 0, Batch loss: 2.2429308891296387\n",
            "Local user 1: Local epoch: 0, Batch loss: 2.2384824752807617\n",
            "Local user 8: Local epoch: 0, Batch loss: 2.2345097064971924\n",
            "Global epoch 8: Test set: Avg. loss: 2.1640, Accuracy: 2257/10000 (23%)\n",
            "\n",
            "GLOBAL EPOCH 9\n",
            "Local user 4: Local epoch: 0, Batch loss: 2.3007872104644775\n",
            "Local user 1: Local epoch: 0, Batch loss: 2.279268264770508\n",
            "Local user 0: Local epoch: 0, Batch loss: 2.284872531890869\n",
            "Global epoch 9: Test set: Avg. loss: 2.2684, Accuracy: 1079/10000 (11%)\n",
            "\n",
            "GLOBAL EPOCH 10\n",
            "Local user 8: Local epoch: 0, Batch loss: 2.273723602294922\n",
            "Local user 3: Local epoch: 0, Batch loss: 2.2687795162200928\n",
            "Local user 4: Local epoch: 0, Batch loss: 2.269798517227173\n",
            "Global epoch 10: Test set: Avg. loss: 2.2305, Accuracy: 1808/10000 (18%)\n",
            "\n",
            "GLOBAL EPOCH 11\n",
            "Local user 6: Local epoch: 0, Batch loss: 2.238091230392456\n",
            "Local user 9: Local epoch: 0, Batch loss: 2.237791061401367\n",
            "Local user 3: Local epoch: 0, Batch loss: 2.2388789653778076\n",
            "Global epoch 11: Test set: Avg. loss: 2.1118, Accuracy: 3977/10000 (40%)\n",
            "\n",
            "GLOBAL EPOCH 12\n",
            "Local user 0: Local epoch: 0, Batch loss: 2.1505422592163086\n",
            "Local user 8: Local epoch: 0, Batch loss: 2.146662712097168\n",
            "Local user 1: Local epoch: 0, Batch loss: 2.1447412967681885\n",
            "Global epoch 12: Test set: Avg. loss: 1.8496, Accuracy: 4520/10000 (45%)\n",
            "\n",
            "GLOBAL EPOCH 13\n",
            "Local user 8: Local epoch: 0, Batch loss: 2.00113844871521\n",
            "Local user 6: Local epoch: 0, Batch loss: 2.0038323402404785\n",
            "Local user 5: Local epoch: 0, Batch loss: 2.0146570205688477\n",
            "Global epoch 13: Test set: Avg. loss: 1.6119, Accuracy: 5754/10000 (58%)\n",
            "\n",
            "GLOBAL EPOCH 14\n",
            "Local user 6: Local epoch: 0, Batch loss: 1.8395510911941528\n",
            "Local user 9: Local epoch: 0, Batch loss: 1.8385472297668457\n",
            "Local user 3: Local epoch: 0, Batch loss: 1.8486944437026978\n",
            "Global epoch 14: Test set: Avg. loss: 1.2606, Accuracy: 6559/10000 (66%)\n",
            "\n",
            "GLOBAL EPOCH 15\n",
            "Local user 6: Local epoch: 0, Batch loss: 1.7185271978378296\n",
            "Local user 1: Local epoch: 0, Batch loss: 1.685060977935791\n",
            "Local user 9: Local epoch: 0, Batch loss: 1.691166877746582\n",
            "Global epoch 15: Test set: Avg. loss: 1.3949, Accuracy: 5990/10000 (60%)\n",
            "\n",
            "GLOBAL EPOCH 16\n",
            "Local user 5: Local epoch: 0, Batch loss: 1.7228246927261353\n",
            "Local user 6: Local epoch: 0, Batch loss: 1.7248518466949463\n",
            "Local user 2: Local epoch: 0, Batch loss: 1.7164005041122437\n",
            "Global epoch 16: Test set: Avg. loss: 1.1512, Accuracy: 6864/10000 (69%)\n",
            "\n",
            "GLOBAL EPOCH 17\n",
            "Local user 4: Local epoch: 0, Batch loss: 1.5231964588165283\n",
            "Local user 9: Local epoch: 0, Batch loss: 1.5285699367523193\n",
            "Local user 8: Local epoch: 0, Batch loss: 1.5332669019699097\n",
            "Global epoch 17: Test set: Avg. loss: 1.0108, Accuracy: 6951/10000 (70%)\n",
            "\n",
            "GLOBAL EPOCH 18\n",
            "Local user 8: Local epoch: 0, Batch loss: 1.4994573593139648\n",
            "Local user 1: Local epoch: 0, Batch loss: 1.5153130292892456\n",
            "Local user 6: Local epoch: 0, Batch loss: 1.5234521627426147\n",
            "Global epoch 18: Test set: Avg. loss: 1.1710, Accuracy: 6831/10000 (68%)\n",
            "\n",
            "GLOBAL EPOCH 19\n",
            "Local user 3: Local epoch: 0, Batch loss: 1.5940302610397339\n",
            "Local user 1: Local epoch: 0, Batch loss: 1.5538302659988403\n",
            "Local user 9: Local epoch: 0, Batch loss: 1.5462373495101929\n",
            "Global epoch 19: Test set: Avg. loss: 1.1573, Accuracy: 6992/10000 (70%)\n",
            "\n",
            "GLOBAL EPOCH 20\n",
            "Local user 6: Local epoch: 0, Batch loss: 1.4726712703704834\n",
            "Local user 2: Local epoch: 0, Batch loss: 1.4558929204940796\n",
            "Local user 7: Local epoch: 0, Batch loss: 1.4773166179656982\n",
            "Global epoch 20: Test set: Avg. loss: 0.8242, Accuracy: 7959/10000 (80%)\n",
            "\n",
            "GLOBAL EPOCH 21\n",
            "Local user 0: Local epoch: 0, Batch loss: 1.3474375009536743\n",
            "Local user 7: Local epoch: 0, Batch loss: 1.3135777711868286\n",
            "Local user 1: Local epoch: 0, Batch loss: 1.3378815650939941\n",
            "Global epoch 21: Test set: Avg. loss: 0.8033, Accuracy: 7565/10000 (76%)\n",
            "\n",
            "GLOBAL EPOCH 22\n",
            "Local user 3: Local epoch: 0, Batch loss: 1.3329033851623535\n",
            "Local user 6: Local epoch: 0, Batch loss: 1.3420336246490479\n",
            "Local user 4: Local epoch: 0, Batch loss: 1.2967242002487183\n",
            "Global epoch 22: Test set: Avg. loss: 0.8509, Accuracy: 7665/10000 (77%)\n",
            "\n",
            "GLOBAL EPOCH 23\n",
            "Local user 6: Local epoch: 0, Batch loss: 1.31886625289917\n",
            "Local user 3: Local epoch: 0, Batch loss: 1.2997417449951172\n",
            "Local user 5: Local epoch: 0, Batch loss: 1.3331336975097656\n",
            "Global epoch 23: Test set: Avg. loss: 0.9432, Accuracy: 7497/10000 (75%)\n",
            "\n",
            "GLOBAL EPOCH 24\n",
            "Local user 5: Local epoch: 0, Batch loss: 1.3247156143188477\n",
            "Local user 8: Local epoch: 0, Batch loss: 1.3007588386535645\n",
            "Local user 1: Local epoch: 0, Batch loss: 1.3318586349487305\n",
            "Global epoch 24: Test set: Avg. loss: 0.7437, Accuracy: 7815/10000 (78%)\n",
            "\n",
            "GLOBAL EPOCH 25\n",
            "Local user 3: Local epoch: 0, Batch loss: 1.1840561628341675\n",
            "Local user 9: Local epoch: 0, Batch loss: 1.1797717809677124\n",
            "Local user 8: Local epoch: 0, Batch loss: 1.1756751537322998\n",
            "Global epoch 25: Test set: Avg. loss: 0.6863, Accuracy: 7969/10000 (80%)\n",
            "\n",
            "GLOBAL EPOCH 26\n",
            "Local user 8: Local epoch: 0, Batch loss: 1.1271733045578003\n",
            "Local user 1: Local epoch: 0, Batch loss: 1.1512303352355957\n",
            "Local user 5: Local epoch: 0, Batch loss: 1.1851040124893188\n",
            "Global epoch 26: Test set: Avg. loss: 0.6645, Accuracy: 8119/10000 (81%)\n",
            "\n",
            "GLOBAL EPOCH 27\n",
            "Local user 2: Local epoch: 0, Batch loss: 1.1037031412124634\n",
            "Local user 0: Local epoch: 0, Batch loss: 1.118179440498352\n",
            "Local user 3: Local epoch: 0, Batch loss: 1.084671139717102\n",
            "Global epoch 27: Test set: Avg. loss: 0.5744, Accuracy: 8548/10000 (85%)\n",
            "\n",
            "GLOBAL EPOCH 28\n",
            "Local user 6: Local epoch: 0, Batch loss: 1.0253349542617798\n",
            "Local user 8: Local epoch: 0, Batch loss: 0.9957937002182007\n",
            "Local user 9: Local epoch: 0, Batch loss: 1.0020581483840942\n",
            "Global epoch 28: Test set: Avg. loss: 0.5105, Accuracy: 8583/10000 (86%)\n",
            "\n",
            "GLOBAL EPOCH 29\n",
            "Local user 2: Local epoch: 0, Batch loss: 0.965169370174408\n",
            "Local user 1: Local epoch: 0, Batch loss: 0.9803553819656372\n",
            "Local user 5: Local epoch: 0, Batch loss: 0.9894008040428162\n",
            "Global epoch 29: Test set: Avg. loss: 0.4807, Accuracy: 8521/10000 (85%)\n",
            "\n",
            "GLOBAL EPOCH 30\n",
            "Local user 1: Local epoch: 0, Batch loss: 0.9589443206787109\n",
            "Local user 2: Local epoch: 0, Batch loss: 0.9381170272827148\n",
            "Local user 9: Local epoch: 0, Batch loss: 0.9285509586334229\n",
            "Global epoch 30: Test set: Avg. loss: 0.4795, Accuracy: 8435/10000 (84%)\n",
            "\n",
            "GLOBAL EPOCH 31\n",
            "Local user 3: Local epoch: 0, Batch loss: 0.9326543807983398\n",
            "Local user 0: Local epoch: 0, Batch loss: 0.9365507960319519\n",
            "Local user 6: Local epoch: 0, Batch loss: 0.9194373488426208\n",
            "Global epoch 31: Test set: Avg. loss: 0.5050, Accuracy: 8317/10000 (83%)\n",
            "\n",
            "GLOBAL EPOCH 32\n",
            "Local user 8: Local epoch: 0, Batch loss: 0.9050055146217346\n",
            "Local user 5: Local epoch: 0, Batch loss: 0.9583616256713867\n",
            "Local user 0: Local epoch: 0, Batch loss: 0.9404839873313904\n",
            "Global epoch 32: Test set: Avg. loss: 0.5156, Accuracy: 8179/10000 (82%)\n",
            "\n",
            "GLOBAL EPOCH 33\n",
            "Local user 2: Local epoch: 0, Batch loss: 0.9234265089035034\n",
            "Local user 9: Local epoch: 0, Batch loss: 0.938693106174469\n",
            "Local user 4: Local epoch: 0, Batch loss: 0.9272090792655945\n",
            "Global epoch 33: Test set: Avg. loss: 0.4964, Accuracy: 8327/10000 (83%)\n",
            "\n",
            "GLOBAL EPOCH 34\n",
            "Local user 9: Local epoch: 0, Batch loss: 0.9099148511886597\n",
            "Local user 7: Local epoch: 0, Batch loss: 0.8893144726753235\n",
            "Local user 2: Local epoch: 0, Batch loss: 0.9261946082115173\n",
            "Global epoch 34: Test set: Avg. loss: 0.4465, Accuracy: 8555/10000 (86%)\n",
            "\n",
            "GLOBAL EPOCH 35\n",
            "Local user 0: Local epoch: 0, Batch loss: 0.8810656070709229\n",
            "Local user 2: Local epoch: 0, Batch loss: 0.854616105556488\n",
            "Local user 9: Local epoch: 0, Batch loss: 0.8612354397773743\n",
            "Global epoch 35: Test set: Avg. loss: 0.4743, Accuracy: 8341/10000 (83%)\n",
            "\n",
            "GLOBAL EPOCH 36\n",
            "Local user 9: Local epoch: 0, Batch loss: 0.9093404412269592\n",
            "Local user 7: Local epoch: 0, Batch loss: 0.9119051098823547\n",
            "Local user 5: Local epoch: 0, Batch loss: 0.9251545667648315\n",
            "Global epoch 36: Test set: Avg. loss: 0.4701, Accuracy: 8459/10000 (85%)\n",
            "\n",
            "GLOBAL EPOCH 37\n",
            "Local user 6: Local epoch: 0, Batch loss: 0.9222062826156616\n",
            "Local user 9: Local epoch: 0, Batch loss: 0.9227627515792847\n",
            "Local user 7: Local epoch: 0, Batch loss: 0.8923076391220093\n",
            "Global epoch 37: Test set: Avg. loss: 0.4881, Accuracy: 8457/10000 (85%)\n",
            "\n",
            "GLOBAL EPOCH 38\n",
            "Local user 6: Local epoch: 0, Batch loss: 0.9299915432929993\n",
            "Local user 5: Local epoch: 0, Batch loss: 0.9222669005393982\n",
            "Local user 1: Local epoch: 0, Batch loss: 0.9312871694564819\n",
            "Global epoch 38: Test set: Avg. loss: 0.4242, Accuracy: 8849/10000 (88%)\n",
            "\n",
            "GLOBAL EPOCH 39\n",
            "Local user 2: Local epoch: 0, Batch loss: 0.8056045770645142\n",
            "Local user 8: Local epoch: 0, Batch loss: 0.8082675933837891\n",
            "Local user 4: Local epoch: 0, Batch loss: 0.8388072848320007\n",
            "Global epoch 39: Test set: Avg. loss: 0.3837, Accuracy: 8693/10000 (87%)\n",
            "\n",
            "GLOBAL EPOCH 40\n",
            "Local user 7: Local epoch: 0, Batch loss: 0.7837765216827393\n",
            "Local user 3: Local epoch: 0, Batch loss: 0.8159400820732117\n",
            "Local user 8: Local epoch: 0, Batch loss: 0.7904353141784668\n",
            "Global epoch 40: Test set: Avg. loss: 0.3927, Accuracy: 8634/10000 (86%)\n",
            "\n",
            "GLOBAL EPOCH 41\n",
            "Local user 2: Local epoch: 0, Batch loss: 0.7938932180404663\n",
            "Local user 6: Local epoch: 0, Batch loss: 0.8070092797279358\n",
            "Local user 5: Local epoch: 0, Batch loss: 0.8117735385894775\n",
            "Global epoch 41: Test set: Avg. loss: 0.3720, Accuracy: 8731/10000 (87%)\n",
            "\n",
            "GLOBAL EPOCH 42\n",
            "Local user 5: Local epoch: 0, Batch loss: 0.780600368976593\n",
            "Local user 3: Local epoch: 0, Batch loss: 0.805795431137085\n",
            "Local user 9: Local epoch: 0, Batch loss: 0.7609588503837585\n",
            "Global epoch 42: Test set: Avg. loss: 0.3823, Accuracy: 8790/10000 (88%)\n",
            "\n",
            "GLOBAL EPOCH 43\n",
            "Local user 9: Local epoch: 0, Batch loss: 0.7982771992683411\n",
            "Local user 5: Local epoch: 0, Batch loss: 0.8003067374229431\n",
            "Local user 3: Local epoch: 0, Batch loss: 0.8053657412528992\n",
            "Global epoch 43: Test set: Avg. loss: 0.3701, Accuracy: 8648/10000 (86%)\n",
            "\n",
            "GLOBAL EPOCH 44\n",
            "Local user 0: Local epoch: 0, Batch loss: 0.7972906231880188\n",
            "Local user 8: Local epoch: 0, Batch loss: 0.779558539390564\n",
            "Local user 7: Local epoch: 0, Batch loss: 0.7613142728805542\n",
            "Global epoch 44: Test set: Avg. loss: 0.4179, Accuracy: 8674/10000 (87%)\n",
            "\n",
            "GLOBAL EPOCH 45\n",
            "Local user 1: Local epoch: 0, Batch loss: 0.8522711396217346\n",
            "Local user 0: Local epoch: 0, Batch loss: 0.8268929123878479\n",
            "Local user 4: Local epoch: 0, Batch loss: 0.8211069107055664\n",
            "Global epoch 45: Test set: Avg. loss: 0.3646, Accuracy: 8913/10000 (89%)\n",
            "\n",
            "GLOBAL EPOCH 46\n",
            "Local user 5: Local epoch: 0, Batch loss: 0.784927248954773\n",
            "Local user 4: Local epoch: 0, Batch loss: 0.7660143375396729\n",
            "Local user 8: Local epoch: 0, Batch loss: 0.7898777723312378\n",
            "Global epoch 46: Test set: Avg. loss: 0.3562, Accuracy: 8879/10000 (89%)\n",
            "\n",
            "GLOBAL EPOCH 47\n",
            "Local user 3: Local epoch: 0, Batch loss: 0.7713901400566101\n",
            "Local user 6: Local epoch: 0, Batch loss: 0.7607296705245972\n",
            "Local user 5: Local epoch: 0, Batch loss: 0.7982088923454285\n",
            "Global epoch 47: Test set: Avg. loss: 0.3361, Accuracy: 8968/10000 (90%)\n",
            "\n",
            "GLOBAL EPOCH 48\n",
            "Local user 1: Local epoch: 0, Batch loss: 0.7500163316726685\n",
            "Local user 2: Local epoch: 0, Batch loss: 0.736315906047821\n",
            "Local user 7: Local epoch: 0, Batch loss: 0.7327387928962708\n",
            "Global epoch 48: Test set: Avg. loss: 0.3179, Accuracy: 8967/10000 (90%)\n",
            "\n",
            "GLOBAL EPOCH 49\n",
            "Local user 3: Local epoch: 0, Batch loss: 0.7370877861976624\n",
            "Local user 7: Local epoch: 0, Batch loss: 0.7241684794425964\n",
            "Local user 9: Local epoch: 0, Batch loss: 0.706734836101532\n",
            "Global epoch 49: Test set: Avg. loss: 0.3324, Accuracy: 8913/10000 (89%)\n",
            "\n",
            "GLOBAL EPOCH 50\n",
            "Local user 7: Local epoch: 0, Batch loss: 0.7112259864807129\n",
            "Local user 3: Local epoch: 0, Batch loss: 0.7583495378494263\n",
            "Local user 1: Local epoch: 0, Batch loss: 0.7624547481536865\n",
            "Global epoch 50: Test set: Avg. loss: 0.3313, Accuracy: 8831/10000 (88%)\n",
            "\n",
            "GLOBAL EPOCH 51\n",
            "Local user 6: Local epoch: 0, Batch loss: 0.7427772879600525\n",
            "Local user 9: Local epoch: 0, Batch loss: 0.7397306561470032\n",
            "Local user 2: Local epoch: 0, Batch loss: 0.7317389845848083\n",
            "Global epoch 51: Test set: Avg. loss: 0.3649, Accuracy: 8823/10000 (88%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1tHLIoZfTGz"
      },
      "source": [
        "Finally we plot our results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DnsrG5jfSjm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "aaf8cea6-8a0b-4e5e-bede-91b1964f5868"
      },
      "source": [
        "fig = plt.figure()\r\n",
        "local_epoch_factor = local_epochs if not fed_sgd else 1\r\n",
        "train_counter = [i*(60000 // user_count) for i in range((c_epochs * active_user_count) * local_epoch_factor)]\r\n",
        "plt.plot(train_counter, train_losses, color='blue')\r\n",
        "test_counter = [i*(60000 // user_count * active_user_count * local_epoch_factor) for i in range(c_epochs + 1)]\r\n",
        "plt.scatter(test_counter, test_losses, color='red')\r\n",
        "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\r\n",
        "plt.xlabel('number of training examples seen')\r\n",
        "plt.ylabel('negative log likelihood loss')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'negative log likelihood loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}